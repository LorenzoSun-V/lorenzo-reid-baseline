# encoding: utf-8
"""
@author:  lorenzo
@contact: baiyingpoi123@gmail.com
"""
import argparse
import logging
import os
import sys
import torch
from pytorch_nndct import get_pruning_runner
from torch.nn.parallel import DistributedDataParallel
from pytorch_nndct import QatProcessor

sys.path.append('.')
from config.config import get_cfg
from playreid.utils import comm
from playreid.data import build_reid_train_loader, build_reid_sub_test_loader, build_reid_test_loader
from playreid.engine.engine import do_train, do_test, auto_scale_hyperparams, default_setup, get_evaluator
from playreid.engine.lanuch import launch
from playreid.modeling import build_quant_model, build_model
from playreid.utils.checkpoint import Checkpointer
from playreid.utils.file_io import find_prune_folder, PathManager


def default_argument_parser():
    """
    Create a parser with some common arguments used.
    Returns:
        argparse.ArgumentParser:
    """
    parser = argparse.ArgumentParser(description="Lorenzo ReID Baseline Training")
    parser.add_argument("-f", "--config-file", default="/workspace/lorenzo/ReID/lorenzo-reid-baseline/configs/Market1501/bagtricks_R50.yml", type=str, help="path to config file")
    parser.add_argument("-s", "--sparsity", type=float, default=0.5, help="sparsity ratio of retrain")
    parser.add_argument("-m", "--mode", default="iter", choices=["iter", "nas", "ofa"], help="pruning method")
    parser.add_argument("-d", "--num-gpus", type=int, default=1, help="number of gpus *per machine*")
    parser.add_argument("--num-machines", type=int, default=1, help="total number of machines")
    parser.add_argument("--machine-rank", type=int, default=0, help="the rank of this machine (unique per machine)")
    port = 2 ** 15 + 2 ** 14 + hash(os.getuid() if sys.platform != "win32" else 1) % 2 ** 14
    parser.add_argument("--dist-url", default="tcp://127.0.0.1:{}".format(port))
    parser.add_argument("-q", '--quant-mode', default='deploy', choices=['train', 'deploy', 'test'],
                        help='quantization mode. train: train float model, deploy: export xmodel, test: evaluate quantized model')    
    # parser.add_argument("--dump-xmodel", action="store_true", help="dump xmodel after test")
    parser.add_argument("opts", help="Modify config options using the command-line", default=None, nargs=argparse.REMAINDER)
    return parser

    
def setup(args, folder_name):
    """
    Create configs and perform basic setups.
    """
    # This function loads default configuration written in ./config/default.py .
    cfg = get_cfg()
    # Merge configs from a given yaml file.
    cfg.merge_from_file(args.config_file)
    # Merge configs from list generated by args.opts
    cfg.merge_from_list(args.opts)  # ['MODEL.DEVICE', 'cuda:0']
    # if args.dump_xmodel:
    #     cfg.TEST.IMS_PER_BATCH = 1
    #     cfg.MODEL.DEVICE = 'cpu'
    cfg.MODEL.PRETRAIN = False
    cfg.MODEL.BACKBONE.PRETRAIN = False
    log_root_dir = cfg.OUTPUT_DIR
    cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, 'QAT', folder_name, f'sparsity_{args.sparsity}')
    cfg.freeze()
    default_setup(cfg, args, f'log_qat_{args.quant_mode}.txt')
    return cfg, log_root_dir


def main(args):
    if args.sparsity != 0:
        folder_name = find_prune_folder(args.mode)
    else:
        folder_name = "original_pth"
    cfg, log_root_dir = setup(args, folder_name)
    data_loader = build_reid_train_loader(cfg)
    cfg = auto_scale_hyperparams(cfg, data_loader.dataset.num_classes)
    # model = build_model(cfg)
    model = build_quant_model(cfg)

    input_signature = torch.randn([1, 3, cfg.INPUT.SIZE_TEST[0], cfg.INPUT.SIZE_TEST[1]], dtype=torch.float32)
    input_signature = input_signature.to(torch.device(cfg.MODEL.DEVICE))
    if args.sparsity != 0:
        model_path = os.path.join(log_root_dir, folder_name, f"sparsity_{args.sparsity}", f"model_slim_{args.sparsity}.pth")
        if not PathManager.isfile(model_path):
            raise RuntimeError(f"No test weight path in {model_path}! Double check your cfg.MODEL.TEST_WEIGHTS!")
        prune_method = folder_name[:-6]
        pruning_runner = get_pruning_runner(model, input_signature, prune_method)
        if prune_method == "iterative":
            model = pruning_runner.prune(removal_ratio=args.sparsity, mode='slim')
        elif prune_method == "one_step":
            model = pruning_runner.prune(removal_ratio=args.sparsity, mode='slim')
        Checkpointer(model).load(model_path)
    else:
        model_path = os.path.join(log_root_dir, "model_best.pth")
        Checkpointer(model).load(model_path)

    distributed = comm.get_world_size() > 1
    if distributed:
        model = DistributedDataParallel(model, device_ids=[comm.get_local_rank()], broadcast_buffers=False)
    # do_test(cfg, model)
    # for module in model.modules():
    #     print(type(module))
    # exit(0)
    qat_processor = QatProcessor(model, input_signature, bitwidth=8)
    if args.quant_mode == "train":
        quantized_model = qat_processor.trainable_model()
        do_train(cfg, quantized_model, data_loader, qat=True)
        deployable_model = qat_processor.to_deployable(quantized_model, cfg.OUTPUT_DIR)
        do_test(cfg, deployable_model)
    elif args.quant_mode == "deploy":
        deployable_model = qat_processor.deployable_model(cfg.OUTPUT_DIR, used_for_xmodel=True)#.cpu()
        # do_test(cfg, deployable_model)
        # sub_loader = build_reid_sub_test_loader(cfg, dataset_name=cfg.DATASETS.TESTS[0])
        deployable_model.eval()
        # from tqdm import tqdm
        # for data in tqdm(sub_loader):
        #     deployable_model(data["images"].cpu())
        tmp_input = torch.randn([1, 3, 256, 128], dtype=torch.float32).to(torch.device('cpu'))
        tmp_output = deployable_model(tmp_input)
        qat_processor.export_xmodel(cfg.OUTPUT_DIR, deploy_check=True)
    elif args.quant_mode == "test":
        deployable_model = qat_processor.deployable_model(cfg.OUTPUT_DIR, used_for_xmodel=False)
        do_test(cfg, deployable_model)
    else:
        raise ValueError('mode must be one of ["train", "deploy", "test"]')


if __name__ == "__main__":
    args = default_argument_parser().parse_args()
    print("Command Line Args:", args)
    launch(
        main,
        args.num_gpus,
        num_machines=args.num_machines,
        machine_rank=args.machine_rank,
        dist_url=args.dist_url,
        args=(args,),
    )