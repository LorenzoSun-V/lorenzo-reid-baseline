# encoding: utf-8
"""
@author:  lorenzo
@contact: baiyingpoi123@gmail.com
"""
import argparse
import logging
import os
import sys
import torch
from torch.nn.parallel import DistributedDataParallel
from pytorch_nndct import get_pruning_runner
sys.path.append('.')
from config.config import get_cfg
from playreid.engine.engine import do_test, default_setup
# from playreid.engine.lanuch import launch

from playreid.modeling import build_model, build_quant_model
from playreid.utils import comm
from playreid.utils.checkpoint import Checkpointer
from playreid.utils.file_io import PathManager


def default_argument_parser():
    """
    Create a parser with some common arguments used.
    Returns:
        argparse.ArgumentParser:
    """
    parser = argparse.ArgumentParser(description="Lorenzo ReID Baseline Training")
    parser.add_argument("--config-file", default="/workspace/lorenzo/ReID/lorenzo-reid-baseline/configs/Market1501/bagtricks_R50.yml", type=str, help="path to config file")
    parser.add_argument("-s", "--sparsity", type=float, default=0.5, help="sparsity ratio of model")
    parser.add_argument("--subnet-index", default=None, help="choose which subnet to retrain")
    parser.add_argument("-d", "--num-gpus", type=int, default=1, help="number of gpus *per machine*")
    parser.add_argument("--num-machines", type=int, default=1, help="total number of machines")
    parser.add_argument("--machine-rank", type=int, default=0, help="the rank of this machine (unique per machine)")
    port = 2 ** 15 + 2 ** 14 + hash(os.getuid() if sys.platform != "win32" else 1) % 2 ** 14
    parser.add_argument("--dist-url", default="tcp://127.0.0.1:{}".format(port))
    parser.add_argument("opts", help="Modify config options using the command-line", default=None, nargs=argparse.REMAINDER)
    return parser

    
def setup(args):
    """
    Create configs and perform basic setups.
    """
    # This function loads default configuration written in ./config/default.py .
    cfg = get_cfg()
    # Merge configs from a given yaml file.
    cfg.merge_from_file(args.config_file)
    # Merge configs from list generated by args.opts
    cfg.merge_from_list(args.opts)  # ['MODEL.DEVICE', 'cuda:0']
    cfg.MODEL.PRETRAIN = False
    cfg.MODEL.BACKBONE.PRETRAIN = False
    cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, 'one_step_prune', f'sparsity_{args.sparsity}')
    cfg.freeze()
    default_setup(cfg, args, 'log_slim_model_test.txt')
    return cfg


def main(args):
    cfg = setup(args)
    cfg.defrost()
    model = build_model(cfg)
    # model = build_quant_model(cfg)

    if cfg.MODEL.TEST_WEIGHTS:
        test_weight = cfg.MODEL.TEST_WEIGHTS
    else:
        test_weight = os.path.join(cfg.OUTPUT_DIR, f'model_slim_{args.sparsity}.pth')
    if not PathManager.isfile(test_weight):
        raise RuntimeError(f"No test weight path in {test_weight}! Double check your cfg.MODEL.TEST_WEIGHTS!")

    input_signature = torch.randn([1, 3, 256, 128], dtype=torch.float32)
    input_signature = input_signature.to(torch.device(cfg.MODEL.DEVICE))
    pruning_runner = get_pruning_runner(model, input_signature, 'one_step')
    model = pruning_runner.prune(removal_ratio=args.sparsity, mode='slim', index=args.subnet_index)
    Checkpointer(model).load(test_weight)
    # print(model)
    # exit(0)
    # distributed = comm.get_world_size() > 1
    # if distributed:
    #     model = DistributedDataParallel(model, device_ids=[comm.get_local_rank()], broadcast_buffers=False)  

    return do_test(cfg, model)


if __name__ == "__main__":
    args = default_argument_parser().parse_args()
    print("Command Line Args:", args)
    main(args)
    # launch(
    #     main,
    #     args.num_gpus,
    #     num_machines=args.num_machines,
    #     machine_rank=args.machine_rank,
    #     dist_url=args.dist_url,
    #     args=(args,),
    # )