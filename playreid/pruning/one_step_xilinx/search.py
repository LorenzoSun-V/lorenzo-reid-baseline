# encoding: utf-8
"""
@author:  lorenzo
@contact: baiyingpoi123@gmail.com
"""
import argparse
from collections import OrderedDict
import os
import sys
import torch
from pytorch_nndct import get_pruning_runner

sys.path.append('.')
from config.config import get_cfg
from playreid.data import build_common_train_loader, _train_loader_from_config
from playreid.engine.engine import get_evaluator, auto_scale_hyperparams, default_setup
from playreid.evaluation import print_csv_format, inference_on_dataset
from playreid.modeling import build_model
from playreid.utils.checkpoint import Checkpointer
from playreid.utils.events import EventStorage


def setup(args):
    """
    Create configs and perform basic setups.
    """
    # This function loads default configuration written in ./config/default.py .
    cfg = get_cfg()
    # Merge configs from a given yaml file.
    cfg.merge_from_file(args.config_file)
    # Merge configs from list generated by args.opts
    cfg.merge_from_list(args.opts)  # ['MODEL.DEVICE', 'cuda:0']
    cfg.MODEL.PRETRAIN = False
    cfg.MODEL.BACKBONE.PRETRAIN = False
    cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, 'one_step_prune')
    cfg.freeze()
    default_setup(cfg, args, 'log_search.txt')
    return cfg


def get_gpus(device):
    return [int(i) for i in device.split(',')]


def eval_fn(model, cfg, data_loader, evaluator):
    # results_i: OrderedDict(), the keys are 'Rank-1', 'Rank-5', 'Rank-10', 'mAP', 'mINP', 'metric'
    results_i = inference_on_dataset(model, data_loader, evaluator, flip_test=cfg.TEST.FLIP.ENABLED)
    results_i['dataset'] = cfg.DATASETS.TESTS[0]
    print_csv_format(results_i)
    # print(results_i)
    return results_i['metric']


def calibration_fn(model, test_loader, number_forward=100):
    # data_loader_iter = iter(train_loader)
    model.train()
    print("Adaptive BN start...")
    with EventStorage():
        with torch.no_grad():
            #// 在该情况下原始的reid_train_loader使用的数据预读DataloaderX会造成内存泄漏,所以重新写了一个常规的Dataloader用于calib
            for index, data in enumerate(test_loader):
                # data['images'] = data['images'].to(torch.device('cuda'))
                # data['targets'] = data['targets'].to(torch.device('cuda'))
                # data['camids'] = data['camids'].to(torch.device('cuda'))
                model(data, False)
                if index > number_forward:
                    break
    print("Adaptive BN end...")


def main():
    parser = argparse.ArgumentParser(description="Lorenzo ReID Baseline Pruning")
    parser.add_argument(
        "-f", "--config-file", default="/workspace/lorenzo/ReID/lorenzo-reid-baseline/configs/Market1501/bagtricks_R50.yml", 
        help="path to config file", type=str)
    parser.add_argument("--gpus", type=str, default='0', help="String of available GPU number")
    parser.add_argument("--num-subnet", type=int, default=200, help="number of subnet to search")
    parser.add_argument("-s", "--sparsity", type=float, default=0.5, help="sparsity ratio of model")
    parser.add_argument("opts", help="Modify config options using the command-line", default=None,
                        nargs=argparse.REMAINDER)

    args = parser.parse_args()
    cfg = setup(args)
    gpus = get_gpus(args.gpus)

    model_path = os.path.join(os.path.dirname(cfg.OUTPUT_DIR), 'model_best.pth')
    # init reid model & load trained pth
    cfg = auto_scale_hyperparams(cfg, _train_loader_from_config(cfg)['train_set'].num_classes)
    model = build_model(cfg)
    Checkpointer(model).load(model_path)
    data_loader, evaluator = get_evaluator(cfg, cfg.DATASETS.TESTS[0])
    # print(model.backbone.layer4.2.conv3)
    # calibration_fn(model, train_loader)
    # return

    input_signature = torch.randn([1, 3, 256, 128], dtype=torch.float32)
    input_signature = input_signature.to(torch.device(cfg.MODEL.DEVICE))
    pruning_runner = get_pruning_runner(model, input_signature, 'one_step')

    pruning_runner.search(
        gpus=gpus,
        calibration_fn=calibration_fn,
        calib_args=(data_loader,),
        num_subnet=args.num_subnet,
        removal_ratio=args.sparsity,
        excludes=[model.backbone.layer4[2].conv3],
        eval_fn=eval_fn,
        eval_args=(cfg, data_loader, evaluator)
    )


if __name__ == "__main__":
    main()